{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB8XWli0GsfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchtext \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sshmxz84G_Zt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c499e19a-9e88-4694-b5af-e78051830f4c"
      },
      "source": [
        "#Load data\n",
        "TEXT = torchtext.data.Field(lower=True, include_lengths=True, batch_first=True)\n",
        "LABEL = torchtext.data.Field(sequential=False)\n",
        "\n",
        "train,test = torchtext.datasets.IMDB.splits(TEXT, LABEL)\n",
        "\n",
        "print(\"Total no. of examples in training set :\", len(train))\n",
        "print(\"Total no. of examples in test set :\", len(test))\n",
        "print(\"Lables : \", set(train.label))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total no. of examples in training set : 25000\n",
            "Total no. of examples in test set : 25000\n",
            "Lables :  {'neg', 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0bn2TxNqtKE",
        "colab_type": "code",
        "outputId": "254f44e6-9d52-4dcd-9b14-03387a57acf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#check gpu\n",
        "if torch.cuda.is_available():\n",
        "    cuda0 = torch.device(\"cuda:0\") \n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    cuda0 = torch.device(\"cpu\")\n",
        "    print(\"Running on the CPU\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on the GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eq0DTngSN5g",
        "colab_type": "text"
      },
      "source": [
        "### Using pre-trained embedding (Glove)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nItFNV4GShzh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.vocab import GloVe  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOxpE1CZVzMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initialize glove embeddings\n",
        "TEXT.build_vocab(train, vectors=GloVe(name='6B', dim=200)) # This will download 862 MB of pre-trained vectors \n",
        "LABEL.build_vocab(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWwEcD7wtUJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMSentimentAnalysis(nn.Module):\n",
        "  def __init__(self, vocab_size ,embedding_dim, hidden_dim1 ,no_of_layers2,output_dim, bidirectional, dropout):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(num_embeddings=vocab_size, \n",
        "                                  embedding_dim=embedding_dim)\n",
        "    self.lstm1 = nn.LSTM(input_size= embedding_dim, \n",
        "                        hidden_size= hidden_dim1, \n",
        "                        num_layers= no_of_layers1, \n",
        "                        batch_first=True, \n",
        "                        bidirectional = bidirectional,\n",
        "                        dropout=dropout) \n",
        "    self.fc1 = nn.Linear(hidden_dim1, 16)\n",
        "    self.fc2 = nn.Linear(16, output_dim)\n",
        "\n",
        "\n",
        "  def forward(self,text,text_length):\n",
        "    #text = [batch size,sent_length]\n",
        "    embedded = self.embedding(text)\n",
        "    #embedded = [batch_size, sent_len, emb_dim]\n",
        "\n",
        "    packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded,\n",
        "                                                        lengths=text_length, \n",
        "                                                        batch_first=True)\n",
        "\n",
        "    packed_output, (hidden, cell) = self.lstm1(packed_embedded)\n",
        "    \n",
        "    hidden = hidden [-2,:,:]\n",
        "\n",
        "    out = F.relu(self.fc1(hidden))\n",
        "    out = self.fc2(out)\n",
        "\n",
        "    return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvt7ofkxrKl2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Hyperparameters\n",
        "vocab_size = len(TEXT.vocab)\n",
        "embedding_dim = 128\n",
        "hidden_dim1 = 32\n",
        "no_of_layers1 = 4\n",
        "output_dim = 2\n",
        "bidirectional = False\n",
        "dropout = 0.2\n",
        "no_of_epoches = 35\n",
        "batch_s = 512\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKgZUfZkAIXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define model\n",
        "model = LSTMSentimentAnalysis(vocab_size ,embedding_dim, hidden_dim1,no_of_layers1, output_dim, bidirectional, dropout)\n",
        "#define optimizer\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "#define loss \n",
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vToB2fmu8qoM",
        "colab_type": "code",
        "outputId": "72bfe424-19f4-4a2e-eff1-d27d411ca8f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTMSentimentAnalysis(\n",
            "  (embedding): Embedding(251639, 128)\n",
            "  (lstm1): LSTM(128, 32, num_layers=4, batch_first=True, dropout=0.2)\n",
            "  (fc1): Linear(in_features=32, out_features=16, bias=True)\n",
            "  (fc2): Linear(in_features=16, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaiUiNaW9cND",
        "colab_type": "code",
        "outputId": "b7781478-f2cc-4171-e03d-c6587f588560",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#transfer model to gpu\n",
        "model.to(cuda0)\n",
        "loss_function.to(cuda0)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrossEntropyLoss()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUDkub5S9Eik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training the network\n",
        "def train_Lstm(model):\n",
        "  for epoch in range(no_of_epoches):\n",
        "    i=0\n",
        "    loss_per_epoch = 0.0\n",
        "    model.train(mode=True)\n",
        "    for batch in train_iter:\n",
        "      i+= 1\n",
        "      text, text_length = batch.text\n",
        "      output = model(text,text_length).squeeze() # convert 1d tensor\n",
        "      batch.label = batch.label -1\n",
        "      loss = loss_function(output, batch.label)\n",
        "      loss.backward() \n",
        "      optimizer.step()\n",
        "\n",
        "      loss_per_epoch+= loss.item()\n",
        "\n",
        "    print(\"EPOCH : {} | Loss : {}\".format(epoch+1,loss_per_epoch/i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_3bTO1VXKJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing the network\n",
        "def evaluate_model(model):\n",
        "  predicted = torch.tensor([0], device=cuda0)\n",
        "  true_classes = torch.tensor([0], device= cuda0)\n",
        "  model.eval() # model in evaluate mode\n",
        "  for batch in test_iter:\n",
        "    text, text_length = batch.text\n",
        "    output = model(text,text_length).squeeze() \n",
        "    _,pred = torch.max(output,1)\n",
        "    predicted = torch.cat([predicted,pred],0)\n",
        "    true_classes = torch.cat([true_classes,batch.label],0)\n",
        "  \n",
        "  predicted = predicted[1:]\n",
        "  true_classes = true_classes[1:]\n",
        "  return predicted, true_classes\n",
        "\n",
        "def accuracy(true_label,predicted):\n",
        "  predicted = predicted+1\n",
        "  dic ={1:0,2:0}\n",
        "  count=0\n",
        "  for i in range(len(predicted)):\n",
        "    if predicted[i]==true_label[i]:\n",
        "      count+=1\n",
        "      if predicted[i].item()==1:\n",
        "        dic[1]+=1\n",
        "      else:\n",
        "        dic[2]+=1\n",
        "\n",
        "  dic[1]=dic[1]/12500\n",
        "  dic[2]=dic[2]/12500\n",
        "  acc= (count*100)/len(predicted)\n",
        "  print(\"Total Accuracy {}% :\", acc)\n",
        "  print(\"Accuracy per class, Positive : {}% | Negative : {}%\".format(dic[1]*100,dic[2]*100))\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct-smTeeMGWM",
        "colab_type": "code",
        "outputId": "f52f9cea-a75b-4c21-e8cb-31fd56c5d93e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "#Converting input data into batches\n",
        "train_iter, test_iter = torchtext.data.BucketIterator.splits(\n",
        "    (train, test), batch_size=batch_s, sort_key = lambda x: len(x.text),\n",
        "    sort_within_batch=True,device=cuda0) \n",
        "\n",
        "# Start training\n",
        "train_Lstm(model)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH : 1 | Loss : 0.6913803207631014\n",
            "EPOCH : 2 | Loss : 0.6477658845940415\n",
            "EPOCH : 3 | Loss : 0.6564758602453737\n",
            "EPOCH : 4 | Loss : 0.6830433509787734\n",
            "EPOCH : 5 | Loss : 0.5764267128341052\n",
            "EPOCH : 6 | Loss : 0.5266346116455234\n",
            "EPOCH : 7 | Loss : 0.48329331923504265\n",
            "EPOCH : 8 | Loss : 0.43350294870989664\n",
            "EPOCH : 9 | Loss : 0.41658115234910226\n",
            "EPOCH : 10 | Loss : 0.342253924632559\n",
            "EPOCH : 11 | Loss : 0.2940977446886958\n",
            "EPOCH : 12 | Loss : 0.22026983724564922\n",
            "EPOCH : 13 | Loss : 0.19451882264443807\n",
            "EPOCH : 14 | Loss : 0.17763513995676625\n",
            "EPOCH : 15 | Loss : 0.1336038029011415\n",
            "EPOCH : 16 | Loss : 0.10936599817811227\n",
            "EPOCH : 17 | Loss : 0.07923401930198377\n",
            "EPOCH : 18 | Loss : 0.08430692355851738\n",
            "EPOCH : 19 | Loss : 0.06326940222358217\n",
            "EPOCH : 20 | Loss : 0.0823183325784547\n",
            "EPOCH : 21 | Loss : 0.0512175767169315\n",
            "EPOCH : 22 | Loss : 0.06757436715522591\n",
            "EPOCH : 23 | Loss : 0.04534472403477649\n",
            "EPOCH : 24 | Loss : 0.05769603452360143\n",
            "EPOCH : 25 | Loss : 0.047000702242462\n",
            "EPOCH : 26 | Loss : 0.039879282081157576\n",
            "EPOCH : 27 | Loss : 0.05039095867197124\n",
            "EPOCH : 28 | Loss : 0.03497642322386406\n",
            "EPOCH : 29 | Loss : 0.03357032144784319\n",
            "EPOCH : 30 | Loss : 0.03229956547444572\n",
            "EPOCH : 31 | Loss : 0.03014712658121574\n",
            "EPOCH : 32 | Loss : 0.03314113383162386\n",
            "EPOCH : 33 | Loss : 0.027977122953731795\n",
            "EPOCH : 34 | Loss : 0.033142047715658436\n",
            "EPOCH : 35 | Loss : 0.027589321107964734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf_0oTfAKc46",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "292cba38-b962-4242-ca1b-13b6a759f669"
      },
      "source": [
        "#Start Testing\n",
        "predicted , true_label = evaluate_model(model)\n",
        "accuracy(true_label,predicted)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Accuracy {}% : 77.192\n",
            "Accuracy per class, Positive : 75.24% | Negative : 79.144%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqQh_sYS0Z5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save the model\n",
        "PATH = './sentiment_analysis.pth'\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD8vPMJ_3l3I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16f9a705-f269-4706-f404-a857ab39452b"
      },
      "source": [
        "#load network\n",
        "net_loaded = LSTMSentimentAnalysis(vocab_size ,embedding_dim, hidden_dim1,no_of_layers1, output_dim, bidirectional, dropout)\n",
        "net_loaded.load_state_dict(torch.load(PATH))\n",
        "print(\"Model Loaded sucessfully.\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Loaded sucessfully.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}